# EAST-Implement: PyTorch Scene Text Detection

A comprehensive PyTorch implementation of **EAST (Efficient and Accurate Scene Text)** detector for scene text detection with complete training, evaluation, and deployment pipeline.

## ğŸ¯ Project Overview

This implementation focuses on:
- **Reproducible Research**: Complete environment specifications and experiment tracking
- **Modern PyTorch**: Best practices with mixed precision, distributed training
- **Production Ready**: Docker containers, ONNX export, REST API serving
- **Educational**: Step-by-step tutorials and comprehensive documentation

## ğŸš€ Quick Start

### 1. Environment Setup

**Option A: Conda (Recommended)**
```bash
git clone https://github.com/SKfaizan-786/EAST_FYP.git
cd EAST_FYP
conda env create -f environment.yml
conda activate east-implement
```

**Option B: pip + virtualenv**
```bash
git clone https://github.com/SKfaizan-786/EAST_FYP.git
cd EAST_FYP
python -m venv venv
source venv/bin/activate  # On Windows: venv\Scripts\activate
pip install -r requirements.txt
```

### 2. Install Package
```bash
pip install -e .
```

### 3. Download ICDAR 2015 Dataset
```bash
python tools/download_dataset.py --dataset icdar2015 --output data/
```

### 4. Train Model
```bash
python tools/train.py --config configs/east_resnet18.yaml
```

## ğŸ“Š Performance Targets

| Metric | Target | Status |
|--------|--------|--------|
| ICDAR 2015 F-score | >77% | ğŸ”„ In Progress |
| Inference Speed | <50ms (RTX 4090) | ğŸ”„ In Progress |
| Training Memory | <8GB VRAM | ğŸ”„ In Progress |
| Test Coverage | >85% | ğŸ”„ In Progress |

## ğŸ—ï¸ Architecture

```
Input Image (3Ã—512Ã—512)
         â†“
   ResNet Backbone 
    (conv2-conv5)
         â†“
  Feature Fusion Network
  (Progressive Upsampling)
         â†“
    Dual-Head Output
  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
  â†“         â†“         â†“
Score Map  Geometry Map
(1Ã—128Ã—128) (8Ã—128Ã—128)
         â†“
   Post-processing
    (NMS + Decode)
         â†“
  Text Detections
   (Quadrilaterals)
```

## ğŸ“ Project Structure

```
EAST_FYP/
â”œâ”€â”€ east/                   # Main package
â”‚   â”œâ”€â”€ models/            # Model architecture
â”‚   â”œâ”€â”€ datasets/          # Data loading
â”‚   â”œâ”€â”€ losses/            # Loss functions
â”‚   â”œâ”€â”€ utils/             # Utilities
â”‚   â””â”€â”€ evaluation/        # Evaluation tools
â”œâ”€â”€ configs/               # Configuration files
â”œâ”€â”€ tools/                 # Training/evaluation scripts
â”œâ”€â”€ notebooks/             # Educational tutorials
â”œâ”€â”€ tests/                 # Unit tests
â”œâ”€â”€ docker/                # Docker configurations
â”œâ”€â”€ docs/                  # Documentation
â”œâ”€â”€ requirements.txt       # Dependencies
â””â”€â”€ setup.py              # Package setup
```

## ğŸ› ï¸ Development Status

### âœ… Completed (Sprint 1)
- [x] GitHub repository setup
- [x] Project structure and requirements
- [x] Configuration system
- [x] Package setup and initialization

### ğŸ”„ In Progress (Sprint 2)
- [ ] ICDAR dataset loader
- [ ] Data preprocessing pipeline
- [ ] Ground truth map generation
- [ ] Data augmentation

### â³ Planned
- [ ] ResNet backbone implementation
- [ ] Feature fusion network
- [ ] Training pipeline
- [ ] Evaluation framework
- [ ] Docker deployment

## ğŸ“š Documentation

- **[Installation Guide](docs/installation.md)** - Detailed setup instructions
- **[Architecture Overview](docs/architecture.md)** - Model design explanation
- **[Training Guide](docs/training.md)** - How to train your own model
- **[API Reference](docs/api.md)** - Complete API documentation
- **[Deployment Guide](docs/deployment.md)** - Production deployment

## ğŸ“ Educational Notebooks

1. **[Architecture Explanation](notebooks/01_architecture_overview.ipynb)** 
2. **[Training Tutorial](notebooks/02_training_tutorial.ipynb)**
3. **[Evaluation Demo](notebooks/03_evaluation_demo.ipynb)**
4. **[Deployment Example](notebooks/04_deployment_example.ipynb)**

## ğŸ³ Docker Deployment

**Training Container**
```bash
docker build -f docker/Dockerfile.train -t east-train .
docker run --gpus all -v $(pwd)/data:/workspace/data east-train
```

**Serving Container**
```bash
docker build -f docker/Dockerfile.serve -t east-serve .
docker run -p 8000:8000 east-serve
```

## ğŸ§ª Testing

Run tests with coverage:
```bash
pytest tests/ --cov=east --cov-report=html
```

## ğŸ“ Citation

If you use this implementation in your research, please cite:

```bibtex
@software{east_implement_2025,
  title={EAST-Implement: PyTorch Scene Text Detection},
  author={Faizan},
  year={2025},
  url={https://github.com/SKfaizan-786/EAST_FYP}
}
```

## ğŸ“„ License

This project is licensed under the MIT License - see the [LICENSE](LICENSE) file for details.

## ğŸ¤ Contributing

1. Fork the repository
2. Create a feature branch (`git checkout -b feature/amazing-feature`)
3. Commit your changes (`git commit -m 'Add amazing feature'`)
4. Push to the branch (`git push origin feature/amazing-feature`)
5. Open a Pull Request

See [CONTRIBUTING.md](CONTRIBUTING.md) for detailed guidelines.

## ğŸ™ Acknowledgments

- Original EAST paper: [Zhou et al., CVPR 2017](https://arxiv.org/abs/1704.03155)
- ICDAR 2015 dataset organizers
- PyTorch team for the excellent framework
- OpenCV contributors for computer vision tools

## ğŸ“ Contact

- **Author**: Faizan
- **GitHub**: [@SKfaizan-786](https://github.com/SKfaizan-786)
- **Project**: [EAST_FYP](https://github.com/SKfaizan-786/EAST_FYP)

---

â­ **Star this repository if you find it helpful!**